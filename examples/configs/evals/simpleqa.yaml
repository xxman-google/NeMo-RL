# SimpleQA Evaluation Configuration
# Reference run: 

# uv run -v examples/run_eval.py --config examples/configs/evals/simpleqa.yaml cluster.gpus_per_node=8
# google/gemma-3-1b-it: https://wandb.ai/yiyiwei-google/eval/runs/47391taq

# uv run -v examples/run_eval.py --config examples/configs/evals/simpleqa.yaml cluster.gpus_per_node=8
# Qwen/Qwen2.5-7B-Instruct: https://wandb.ai/yiyiwei-google/eval/runs/ry068d1x

defaults: "eval.yaml"

generation:
  model_name: "google/gemma-3-4b-it"
#  model_name: "Qwen/Qwen3-235B-A22B"
#   model_name: "Qwen/Qwen2.5-7B-Instruct"
#   model_name: "Qwen/Qwen2.5-Math-1.5B-Instruct"

data:
  system_prompt_file: "examples/prompts/simpleqa.txt"
  dataset_name: "simpleqa"

env:
  math:
    worker_type: "simpleqa"
    # grader_model_name: "gemini-2.5-flash"
    # grader_api_key: ""
    grader_model_name: "gpt-4o"
#    grader_system_message: 
#    grader_temperature:
#    grader_max_tokens: 